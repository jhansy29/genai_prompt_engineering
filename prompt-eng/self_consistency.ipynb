{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the final self-consistent requirement analysis:\n",
      "\n",
      "**SQL Learning Platform Requirement Analysis**\n",
      "\n",
      "**Overview**\n",
      "\n",
      "The SQL learning platform aims to provide a comprehensive and interactive environment for users to learn and practice SQL skills. The platform should be scalable, secure, and user-friendly.\n",
      "\n",
      "**Functional Requirements**\n",
      "\n",
      "1. **User Authentication**: Implement a robust authentication mechanism to ensure only authorized users can access the platform.\n",
      "2. **Knowledge Graph Management**: Develop a knowledge graph that stores SQL concepts, syntax, and semantics. The graph should be able to handle new data additions, updates, and modifications.\n",
      "3. **Exercise and Quiz System**: Create an exercise and quiz system that tracks user progress and provides feedback on correct/incorrect answers.\n",
      "4. **Progress Tracking**: Implement a progress tracking system that monitors users' completion of exercises and quizzes.\n",
      "5. **Feedback Mechanism**: Provide a feedback mechanism that informs users of their mistakes, including explanations for correct/incorrect answers.\n",
      "\n",
      "**Non-Functional Requirements**\n",
      "\n",
      "1. **Performance**: Ensure the platform responds within 2 seconds for user interactions and handle up to 100 concurrent users without significant performance degradation.\n",
      "2. **Security**: Implement data encryption using AES-256 encryption and ensure only authorized users can access the platform.\n",
      "3. **Usability**: Design an intuitive and user-friendly interface with clear instructions and feedback.\n",
      "4. **Scalability**: Develop the platform to handle increasing numbers of users and queries without significant performance degradation.\n",
      "\n",
      "**Constraints and Edge Cases**\n",
      "\n",
      "1. **Data Integrity**: Ensure data integrity by preventing duplicate or inconsistent entries in the knowledge graph.\n",
      "2. **Query Optimization**: Optimize query execution to minimize processing time and improve performance.\n",
      "3. **Error Handling**: Handle errors gracefully, providing informative error messages and suggestions for correction.\n",
      "4. **User Behavior**: Detect and prevent cheating or other forms of exploitation.\n",
      "\n",
      "**Additional Requirements**\n",
      "\n",
      "1. **API Integration**: Provide a RESTful API for integrating with external applications or services.\n",
      "2. **Reporting and Analytics**: Generate reports on user performance, progress, and engagement metrics.\n",
      "\n",
      "**Technical Requirements**\n",
      "\n",
      "1. **Database Management System**: Use a robust database management system to store knowledge graph data.\n",
      "2. **Programming Language**: Develop the platform using a modern programming language (e.g., Python, JavaScript).\n",
      "3. **Front-end Framework**: Utilize a front-end framework (e.g., React, Angular) for building the user interface.\n",
      "\n",
      "This final requirement analysis combines the strongest elements from all three versions, providing a comprehensive and detailed outline of the SQL learning platform's requirements.\n",
      "Time taken: 17.579s\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from _pipeline import create_payload, model_req\n",
    "\n",
    "# Define the Use Case Description\n",
    "USE_CASE_DESCRIPTION = \"\"\"\n",
    "We seek to develop a solution SQL_Guardian, aligned with the Use Case for AI-Powered SQL Learning & Interview Preparation.\n",
    "\n",
    "Our solution aims to provide an interactive learning experience for SQL, guiding users through structured lessons, real-time query execution, and advanced interview preparation using GenAI capabilities.\n",
    "\n",
    "The solution will work as follows:\n",
    "\n",
    "1. **Interactive SQL Learning**: Users can ask SQL-related questions, receive detailed explanations, and see real-world examples.\n",
    "2. **Real-time Query Execution**: The bot provides a built-in SQL execution environment where users can test their queries and receive instant feedback.\n",
    "3. **Automated Query Evaluation**: The bot analyzes user queries, suggests optimizations, and explains execution plans.\n",
    "4. **Interview Preparation Mode**: Offers FAANG-style SQL coding challenges with real-time evaluation and feedback.\n",
    "5. **Personalized Learning Paths**: Tracks user progress and adapts question difficulty based on performance.\n",
    "\"\"\"\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 1: Generate Multiple CoT Prompt Variations\n",
    "# --------------------------------------------\n",
    "\n",
    "cot_prompt_variations = [\n",
    "    f\"\"\"\n",
    "    You are an AI prompt engineering assistant specializing in automated requirement analysis.\n",
    "\n",
    "    ### **Task:**  \n",
    "    Your goal is to **create a Chain of Thought (CoT) prompt** that guides AI to extract a **comprehensive requirement analysis**.\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Identify **Functional, Non-Functional, Constraint-based, and Technical** requirements.  \n",
    "    - Ensure the prompt provides **clear step-by-step instructions** for structured output.  \n",
    "    - Emphasize **AI/ML capabilities, performance tuning, and security**.  \n",
    "\n",
    "    ---\n",
    "    #### **Use Case Description:**\n",
    "    {USE_CASE_DESCRIPTION}\n",
    "\n",
    "    ---\n",
    "    Now, generate a **CoT prompt** for requirement analysis, focusing on AI capabilities and optimization strategies.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    You are an expert in system requirement engineering.\n",
    "\n",
    "    ### **Goal:**  \n",
    "    Develop a structured **Chain of Thought prompt** for AI-based **requirement extraction**.\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Ensure the CoT covers **usability, scalability, security, and integration points**.  \n",
    "    - The prompt should guide AI to consider **API integrations, cloud deployment, and performance trade-offs**.  \n",
    "    - AI should **evaluate each requirement for feasibility and risk factors**.  \n",
    "\n",
    "    ---\n",
    "    #### **Use Case Description:**\n",
    "    {USE_CASE_DESCRIPTION}\n",
    "\n",
    "    ---\n",
    "    Generate a CoT prompt that focuses on **scalability, API development, and cloud-based deployment**.\n",
    "    \"\"\",\n",
    "    f\"\"\"\n",
    "    You are a system architect specializing in AI-powered software solutions.\n",
    "\n",
    "    ### **Task:**  \n",
    "    Create a **highly structured Chain of Thought prompt** for AI-driven **requirement analysis**.\n",
    "\n",
    "    ### **Instructions:**  \n",
    "    - Extract **business logic, AI model needs, database considerations, and security policies**.  \n",
    "    - Ensure the AI-generated CoT prompt provides **deep technical coverage, edge-case handling, and AI explainability**.  \n",
    "\n",
    "    ---\n",
    "    #### **Use Case Description:**\n",
    "    {USE_CASE_DESCRIPTION}\n",
    "\n",
    "    ---\n",
    "    Generate a CoT prompt that prioritizes **technical depth, AI/ML explainability, and security compliance**.\n",
    "    \"\"\"\n",
    "]\n",
    "\n",
    "# Generate three different CoT prompts\n",
    "generated_cot_prompts = []\n",
    "for cot_prompt in cot_prompt_variations:\n",
    "    payload = create_payload(target=\"ollama\",\n",
    "                             model=\"llama3.2:latest\",\n",
    "                             prompt=cot_prompt,\n",
    "                             temperature=0.3,  \n",
    "                             num_ctx=700,\n",
    "                             num_predict=1800)\n",
    "    \n",
    "    time, response = model_req(payload=payload)\n",
    "    generated_cot_prompts.append(response)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 2: Generate Requirement Analysis Three Times\n",
    "# --------------------------------------------\n",
    "\n",
    "requirement_analyses = []\n",
    "for cot_prompt in generated_cot_prompts:\n",
    "    requirement_analysis_prompt = f\"\"\"\n",
    "    You are an AI expert in **requirement analysis**.\n",
    "\n",
    "    The following is a **Chain of Thought prompt** generated for extracting requirements.\n",
    "\n",
    "    ---\n",
    "    ### **Generated CoT Prompt:**\n",
    "    {cot_prompt}\n",
    "\n",
    "    ---\n",
    "    ### **Task:**  \n",
    "    Based on this prompt, generate a **comprehensive requirement analysis** covering:\n",
    "\n",
    "    1. **Functional Requirements**  \n",
    "    2. **Non-Functional Requirements**  \n",
    "    3. **Constraints and Edge Cases**  \n",
    "    4. **Technical Requirements**  \n",
    "    5. **APIs and System Integration Considerations**  \n",
    "\n",
    "    Ensure clarity, structure, and accuracy in the output.\n",
    "    \"\"\"\n",
    "\n",
    "    payload = create_payload(target=\"ollama\",\n",
    "                             model=\"llama3.2:latest\",\n",
    "                             prompt=requirement_analysis_prompt,\n",
    "                             temperature=0.3,  \n",
    "                             num_ctx=800,\n",
    "                             num_predict=2000)\n",
    "\n",
    "    time, response = model_req(payload=payload)\n",
    "    requirement_analyses.append(response)\n",
    "\n",
    "# --------------------------------------------\n",
    "# Step 3: AI Self-Consistency Aggregation\n",
    "# --------------------------------------------\n",
    "\n",
    "self_consistency_prompt = f\"\"\"\n",
    "You are an AI specializing in **requirement analysis validation**.\n",
    "\n",
    "The following are **three independently generated requirement analyses** based on different CoT prompts.\n",
    "\n",
    "---\n",
    "### **Requirement Analysis Version 1:**  \n",
    "{requirement_analyses[0]}\n",
    "\n",
    "---\n",
    "### **Requirement Analysis Version 2:**  \n",
    "{requirement_analyses[1]}\n",
    "\n",
    "---\n",
    "### **Requirement Analysis Version 3:**  \n",
    "{requirement_analyses[2]}\n",
    "\n",
    "---\n",
    "### **Task:**  \n",
    "Your goal is to **compare these versions and extract the most consistent, structured, and detailed answers**.\n",
    "\n",
    "1. **Find common elements across all versions.**  \n",
    "2. **If differences exist, prioritize the most complete and logically structured responses.**  \n",
    "3. **Eliminate inconsistencies or missing details.**  \n",
    "4. **Produce a final, improved requirement analysis that reflects the most accurate responses.**  \n",
    "\n",
    "---\n",
    "Now, generate the **final self-consistent requirement analysis** that combines the strongest elements from all three versions.\n",
    "\"\"\"\n",
    "\n",
    "# Request AI to produce the final, most consistent requirement analysis\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\",\n",
    "                         prompt=self_consistency_prompt,\n",
    "                         temperature=0.3,  \n",
    "                         num_ctx=1000,\n",
    "                         num_predict=2000)\n",
    "\n",
    "time, final_response = model_req(payload=payload)\n",
    "\n",
    "\n",
    "print(final_response)\n",
    "print(f'Time taken: {time}s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Final Self-Consistent Requirement Analysis**\n",
      "\n",
      "The SQL learning platform requires the following features and functionalities:\n",
      "\n",
      "**Core Requirements:**\n",
      "\n",
      "1. **Query Execution**: The system must execute SQL queries accurately and efficiently, handling a minimum of 100 concurrent users without significant performance degradation.\n",
      "2. **Knowledge Graph Management**: The system should manage a comprehensive knowledge graph containing SQL concepts, syntax, and semantics, with mechanisms for adding new data, updating existing information, and preventing duplicate or inconsistent entries.\n",
      "3. **Feedback Mechanism**: Users receive feedback on their answers, including correct/incorrect status and explanations, to improve learning outcomes and prevent cheating.\n",
      "4. **Progress Tracking**: The system tracks users' progress through exercises and quizzes, providing personalized insights into areas of improvement.\n",
      "\n",
      "**Performance Requirements:**\n",
      "\n",
      "1. **Response Time**: The system should respond within a reasonable time frame (e.g., 2 seconds) for user interactions.\n",
      "2. **Scalability**: The system should be able to handle an increasing number of users and queries without significant performance degradation.\n",
      "3. **Query Optimization**: The system optimizes query execution to minimize processing time and improve performance.\n",
      "\n",
      "**Security Requirements:**\n",
      "\n",
      "1. **Data Encryption**: User data, including query results and feedback, is encrypted using AES-256 encryption.\n",
      "2. **Authentication**: Authentication mechanisms ensure only authorized users can access the platform.\n",
      "3. **Error Handling**: The system handles errors gracefully, providing informative error messages and suggestions for correction.\n",
      "\n",
      "**Usability Requirements:**\n",
      "\n",
      "1. **Intuitive Interface**: The interface is intuitive and user-friendly, with clear instructions and feedback.\n",
      "2. **User Experience**: The system provides a seamless and engaging user experience, encouraging users to practice and improve their SQL skills.\n",
      "\n",
      "**Additional Requirements:**\n",
      "\n",
      "1. **API Integration**: The system provides a RESTful API for integrating with external applications or services.\n",
      "2. **Reporting and Analytics**: The system generates reports on user performance, progress, and engagement metrics.\n",
      "\n",
      "**Edge Cases and Constraints:**\n",
      "\n",
      "1. **Data Integrity**: The system ensures data integrity by preventing duplicate or inconsistent entries in the knowledge graph.\n",
      "2. **User Behavior**: The system detects and prevents cheating or other forms of exploitation.\n",
      "\n",
      "This final requirement analysis combines the strongest elements from all three versions, providing a comprehensive and structured set of requirements for the SQL learning platform.\n",
      "Time taken: 13.832s\n"
     ]
    }
   ],
   "source": [
    "# Request AI to produce the final, most consistent requirement analysis\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\",\n",
    "                         prompt=self_consistency_prompt,\n",
    "                         temperature=0.7,  \n",
    "                         num_ctx=1000,\n",
    "                         num_predict=2000)\n",
    "\n",
    "time, final_response = model_req(payload=payload)\n",
    "\n",
    "\n",
    "print(final_response)\n",
    "print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the final, self-consistent requirement analysis:\n",
      "\n",
      "**SQL Learning Platform Requirements**\n",
      "\n",
      "1. **Functional Requirements**\n",
      "\t* The system should be able to store and retrieve SQL concepts, syntax, and semantics in a knowledge graph.\n",
      "\t* Users can interact with the platform through a user-friendly interface, including exercises, quizzes, and feedback mechanisms.\n",
      "\t* The system tracks users' progress through exercises and quizzes, providing feedback on correct/incorrect status and explanations.\n",
      "2. **Non-Functional Requirements**\n",
      "\t* Performance: The system should respond within 2 seconds for user interactions and handle at least 100 concurrent users without significant performance degradation.\n",
      "\t* Security: User data is encrypted using AES-256 encryption, and authentication mechanisms ensure only authorized users can access the platform.\n",
      "\t* Usability: The interface is intuitive and user-friendly, with clear instructions and feedback.\n",
      "3. **Constraints and Edge Cases**\n",
      "\t* Data Integrity: The system ensures data integrity by preventing duplicate or inconsistent entries in the knowledge graph.\n",
      "\t* Query Optimization: The system optimizes query execution to minimize processing time and improve performance.\n",
      "\t* Error Handling: The system handles errors gracefully, providing informative error messages and suggestions for correction.\n",
      "4. **Additional Requirements**\n",
      "\t* API Integration: The system provides a RESTful API for integrating with external applications or services.\n",
      "\t* Reporting and Analytics: The system generates reports on user performance, progress, and engagement metrics.\n",
      "\n",
      "**Assumptions and Dependencies**\n",
      "\n",
      "1. **Hardware and Software**: The platform will run on a cloud-based infrastructure with sufficient resources to handle a large number of users and queries.\n",
      "2. **Database Management**: A relational database (e.g., MySQL) is assumed for storing and retrieving data.\n",
      "3. **Development Tools**: Agile development methodologies, version control systems (e.g., Git), and continuous integration pipelines are recommended.\n",
      "\n",
      "**Risks and Mitigation Strategies**\n",
      "\n",
      "1. **Security Risks**: Implementing robust security measures, such as encryption and access controls, to protect user data and prevent unauthorized access.\n",
      "2. **Performance Degradation**: Regularly monitoring system performance, optimizing query execution, and investing in additional resources to handle increased user loads.\n",
      "3. **User Engagement**: Providing a user-friendly interface, clear instructions, and regular feedback to maintain users' interest and motivation.\n",
      "\n",
      "**Success Metrics**\n",
      "\n",
      "1. **User Adoption**: Tracking the number of registered users and active sessions.\n",
      "2. **User Engagement**: Measuring users' progress, completion rates, and time spent on exercises and quizzes.\n",
      "3. **Platform Performance**: Monitoring system response times, error rates, and overall user satisfaction.\n",
      "\n",
      "By following this requirement analysis, the development team can ensure that the SQL learning platform meets the needs of its target audience while minimizing risks and optimizing performance.\n",
      "Time taken: 27.853s\n"
     ]
    }
   ],
   "source": [
    "# Request AI to produce the final, most consistent requirement analysis\n",
    "payload = create_payload(target=\"ollama\",\n",
    "                         model=\"llama3.2:latest\",\n",
    "                         prompt=self_consistency_prompt,\n",
    "                         temperature=1.0,  \n",
    "                         num_ctx=1000,\n",
    "                         num_predict=2000)\n",
    "\n",
    "time, final_response = model_req(payload=payload)\n",
    "\n",
    "\n",
    "print(final_response)\n",
    "print(f'Time taken: {time}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
